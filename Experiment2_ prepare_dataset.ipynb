{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"How well can a MLP approximate a dot product.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "rmse_best = 0.85\n",
    "rmse_naive = 1.13\n",
    "\n",
    "\n",
    "def GenerateData(emb_dim, num_users, num_items, num_train_samples,\n",
    "                 num_test_samples, num_fresh_samples):\n",
    "    \"\"\"Generates a data set where ground truth is a dot product with noise.\n",
    "  \n",
    "    Each generated training case x is a real valued vector of dimension\n",
    "    2*embedding_dim (this is the concatenation of the two embedding vectors for\n",
    "    which we want to learn the similarity) and a label y that encodes the\n",
    "    similarity.\n",
    "  \n",
    "    The data is generated such that a perfect model (the dot product) will have an\n",
    "    RMSE of rmse_best. The naive model that predicts always 0 will have an RMSE of\n",
    "    rmse_naive. See the paper for more details.\n",
    "  \n",
    "    Args:\n",
    "      emb_dim: the embedding dimension.\n",
    "      num_users: the total number of users.\n",
    "      num_items: the total number of items.\n",
    "      num_train_samples: the size of the training set.\n",
    "      num_test_samples: the size of the first test set.\n",
    "      num_fresh_samples: the size of the second test set.\n",
    "  \n",
    "    Returns:\n",
    "    Three datasets are created:\n",
    "    * train: consists of pairs of user,item embeddings and their label. User and\n",
    "             item embeddings are drawn from a fixed set of <num_user> and\n",
    "             <num_items> embeddings\n",
    "    * test:  same as train but with the constraint that train and test do not\n",
    "             overlap\n",
    "    * fresh: same as train but using fresh embeddings, i.e., embeddings are not\n",
    "             limited to the <num_user> and <num_items> embeddings from train and\n",
    "             test\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate standard deviation of embedding distribution and noise\n",
    "    # distribution such that the data will have the desired RMSE properties.\n",
    "    print('Calculate standard deviation')\n",
    "    sd_noise = rmse_best\n",
    "    sd_emb = np.sqrt(np.sqrt((np.square(rmse_naive)\n",
    "                              - np.square(rmse_best)) / emb_dim))\n",
    "\n",
    "    # Generate the embeddings:\n",
    "    print('Generate the embeddings:')\n",
    "    user_embs = np.random.normal(0, sd_emb, size=[num_users, emb_dim])\n",
    "    item_embs = np.random.normal(0, sd_emb, size=[num_items, emb_dim])\n",
    "\n",
    "    # Sample n combinations of user x item without replacement\n",
    "    num_samples = num_train_samples + num_test_samples\n",
    "    train_x = np.zeros([num_samples * 2, 2, emb_dim], dtype=float)\n",
    "    train_y = np.zeros([num_samples * 2], dtype=float)\n",
    "    sampling_prob = num_samples / (num_users * num_items)\n",
    "    sampling_prob *= 1.1  # oversample to make sure we have enough samples\n",
    "    counter = 0\n",
    "    for u in tqdm(range(num_users), position=0,leave=False, desc='compute train/test'):\n",
    "        for i in range(num_items):\n",
    "            if np.random.uniform() < sampling_prob:\n",
    "                user_emb = user_embs[u]\n",
    "                item_emb = item_embs[i]\n",
    "                train_x[counter][0] = user_emb\n",
    "                train_x[counter][1] = item_emb\n",
    "                train_y[counter] = (\n",
    "                        np.random.normal(0.0, sd_noise) + np.dot(user_emb, item_emb))\n",
    "                counter = counter + 1\n",
    "    counter = np.min([counter, num_samples])\n",
    "\n",
    "    # discard any additional items\n",
    "    print('discard any additional items')\n",
    "    train_x = train_x[:counter, :, :]\n",
    "    train_y = train_y[:counter]\n",
    "\n",
    "    # shuffle\n",
    "    print('shuffle')\n",
    "    p = np.random.permutation(train_x.shape[0])\n",
    "    train_x = train_x[p]\n",
    "    train_y = train_y[p]\n",
    "\n",
    "    # Split into 90% training, 10% testing\n",
    "    print('Split into 90% training, 10% testing')\n",
    "    train_x, test_x = np.split(train_x,\n",
    "                               [int((counter * num_train_samples) / num_samples)])\n",
    "    train_y, test_y = np.split(train_y,\n",
    "                               [int((counter * num_train_samples) / num_samples)])\n",
    "\n",
    "    # Second set of holdout interactions, i.e., embeddings are new:\n",
    "    fresh_x = np.random.normal(0, sd_emb, size=[num_fresh_samples, 2, emb_dim])\n",
    "    fresh_y = np.zeros([num_fresh_samples], dtype=float)\n",
    "    for counter in tqdm(range(num_fresh_samples), position=0,leave=False,desc='Second set of holdout interactions'):\n",
    "        user_emb = fresh_x[counter][0]\n",
    "        item_emb = fresh_x[counter][1]\n",
    "        fresh_y[counter] = (\n",
    "                np.random.normal(0.0, sd_noise) + np.dot(user_emb, item_emb))\n",
    "\n",
    "    return train_x, train_y, test_x, test_y, fresh_x, fresh_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute train/test:   0%|          | 6/4000 [00:00<01:17, 51.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate standard deviation\n",
      "Generate the embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discard any additional items\n",
      "shuffle\n",
      "Split into 90% training, 10% testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples:  (360000, 2, 16)\n",
      "Num test examples:  (40000, 2, 16)\n",
      "Num fresh examples:  (100000, 2, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute train/test:   0%|          | 6/4000 [00:00<01:17, 51.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate standard deviation\n",
      "Generate the embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discard any additional items\n",
      "shuffle\n",
      "Split into 90% training, 10% testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples:  (360000, 2, 32)\n",
      "Num test examples:  (40000, 2, 32)\n",
      "Num fresh examples:  (100000, 2, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute train/test:   0%|          | 6/4000 [00:00<01:21, 49.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate standard deviation\n",
      "Generate the embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discard any additional items\n",
      "shuffle\n",
      "Split into 90% training, 10% testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples:  (360000, 2, 64)\n",
      "Num test examples:  (40000, 2, 64)\n",
      "Num fresh examples:  (100000, 2, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "compute train/test:   0%|          | 6/4000 [00:00<01:12, 54.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate standard deviation\n",
      "Generate the embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discard any additional items\n",
      "shuffle\n",
      "Split into 90% training, 10% testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training examples:  (360000, 2, 128)\n",
      "Num test examples:  (40000, 2, 128)\n",
      "Num fresh examples:  (100000, 2, 128)\n"
     ]
    }
   ],
   "source": [
    "# # Generate data and print some statistics\n",
    "# python approx_dot.py --embedding_dim {16,32,64,128} \\\n",
    "#    --num_users {4000,8000,16000,32000,64000,128000} \\\n",
    "#    --num_items {4000,8000,16000,32000,64000,128000} \\\n",
    "#    --first_layer_mult {1,2,4} --learning_rate 0.001\n",
    "\n",
    "embedding_dims = [16, 32, 64, 128]\n",
    "num_users = 4000#[4000, 8000, 16000, 32000, 64000, 128000]\n",
    "num_items = 4000#[4000, 8000, 16000, 32000, 64000, 128000]\n",
    "\n",
    "for embedding_dim in embedding_dims:\n",
    "    num_samples = num_users * 100  # 100 items per user on average\n",
    "    train_x, train_y, test_x, test_y, fresh_x, fresh_y = GenerateData(\n",
    "        emb_dim=embedding_dim,\n",
    "        num_users=num_users,\n",
    "        num_items=num_items,\n",
    "        num_train_samples=int(num_samples * 0.9),\n",
    "        num_test_samples=int(num_samples * 0.1), num_fresh_samples=100000)\n",
    "\n",
    "    print('Num training examples: ', train_x.shape)\n",
    "    print('Num test examples: ', test_x.shape)\n",
    "    print('Num fresh examples: ', fresh_x.shape)\n",
    "    \n",
    "    # saving\n",
    "    save_spec = f'{embedding_dim}_{num_users}_{num_items}'\n",
    "    np.save(f'train_x_{save_spec}.npy', train_x)\n",
    "    np.save(f'train_y_{save_spec}.npy', train_y)\n",
    "    np.save(f'test_x_{save_spec}.npy', test_x)\n",
    "    np.save(f'test_y_{save_spec}.npy', test_y)\n",
    "    np.save(f'fresh_x_{save_spec}.npy', fresh_x)\n",
    "    np.save(f'fresh_y_{save_spec}.npy', fresh_y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
